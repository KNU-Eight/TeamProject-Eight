from fetch_links_1year import fetch_links_1year
from fetch_article_contents import fetch_article_contents
import os
base_dir = os.path.dirname(__file__)
data_dir = os.path.join(base_dir, "..", "data", "yna_news")

os.makedirs(data_dir, exist_ok=True)

urls_path = os.path.join(data_dir, "urls_1year.json")
articles_path = os.path.join(data_dir, "full_articles_1year.json")

if __name__ == "__main__":
    print("ğŸŸ¢ 3ê°œì›” ì¹˜ ë‰´ìŠ¤ ë§í¬ ìˆ˜ì§‘ ì‹œì‘...")
    fetch_links_1year(
        keywords=["ì „ì„¸ì‚¬ê¸°", "ë³´ì¦ê¸ˆ", "ê¹¡í†µì „ì„¸", "ë³´ì¦ë³´í—˜", "í”¼í•´ì"],
        max_pages=100,
        output_path="data/urls_1year.json"
    )

    print("ğŸŸ¢ 3ê°œì›” ì¹˜ ë‰´ìŠ¤ ë³¸ë¬¸ ìˆ˜ì§‘ ì‹œì‘...")
    fetch_article_contents(
        input_path="data/urls_1year.json",
        output_path="data/full_articles_1year.json"
    )
